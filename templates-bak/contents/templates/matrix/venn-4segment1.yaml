# venn-4segment1 콘텐츠 템플릿 v3.1
# 원본: wooseok1-004.png (네이버 블로그 우석지니)
# 재생성: 2026-01-07 (썸네일 기반 정밀 재현)

content_template:
  id: venn-4segment1
  name: "4분할 벤 다이어그램 (메모리 아키텍처)"
  version: "3.1"
  schema_version: "3.0-svg"
  source: wooseok1-004.png
  source_url: "https://blog.naver.com/wooseokjin/224127136621"
  extracted_at: "2026-01-07T00:00:00Z"

design_meta:
  quality_score: 9.0
  design_intent: venn-4segment
  design_intents:
    - matrix-venn
    - comparison-overlap
  visual_balance: symmetric
  information_density: high
  render_method: svg

canvas:
  reference_width: 960
  reference_height: 540
  aspect_ratio: "16:9"
  viewBox: "0 0 960 540"

layout:
  type: venn
  segments: 4
  overlap: true
  center_element: true

background:
  type: solid
  color: "#FFFFFF"

header:
  has_header: true
  style:
    fill:
      type: gradient
      gradient:
        type: linear
        colors: ["#E8E0F0", "#F0E8F8"]
        angle: 90
  geometry:
    x: 0%
    y: 0%
    cx: 100%
    cy: 14%
  title:
    text: "Breaking the Memory Wall : A Paradigm Shift"
    font_size_ratio: 0.037
    font_weight: bold
    font_color: dark_text
    position: {x: 2%, y: 2.5%}
  subtitle:
    text: "Minimizes data movement and latency by executing computations directly where data resides (Near-Data Processing). Maximizes AI workload throughput by combining the ultra-high bandwidth of HBM with the flexible pooling capabilities of CXL."
    font_size_ratio: 0.015
    font_color: secondary_text
    position: {x: 2%, y: 7%}

# 완전한 인라인 SVG (정밀 재현 v2 - 원본 대각선 배치 반영)
svg_inline: |
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 960 540" width="960" height="540">
    <defs>
      <linearGradient id="headerGrad" x1="0%" y1="0%" x2="100%" y2="0%">
        <stop offset="0%" stop-color="#E8E0F0"/>
        <stop offset="100%" stop-color="#F0E8F8"/>
      </linearGradient>
    </defs>

    <!-- Background -->
    <rect width="960" height="540" fill="#FFFFFF"/>

    <!-- Header Background -->
    <rect x="0" y="0" width="960" height="75" fill="url(#headerGrad)"/>

    <!-- Header Title -->
    <text x="20" y="32" font-family="Arial, sans-serif" font-size="22" font-weight="bold" fill="#333">
      Breaking the Memory Wall : A Paradigm Shift
    </text>
    <text x="20" y="55" font-family="Arial, sans-serif" font-size="9" fill="#666" xml:space="preserve">
      <tspan>Minimizes data movement and latency by executing computations directly where data resides (Near-Data Processing). Maximizes AI workload throughput by</tspan>
    </text>
    <text x="20" y="68" font-family="Arial, sans-serif" font-size="9" fill="#666">
      combining the ultra-high bandwidth of HBM with the flexible pooling capabilities of CXL.
    </text>

    <!-- Venn Diagram - 4 Overlapping Ellipses (대각선 배치) -->
    <g transform="translate(480, 290)">
      <!-- MH - 상단 우측 (Memory Hierarchy) - 원형에 가까운 타원 -->
      <ellipse cx="30" cy="-50" rx="110" ry="80" fill="#DCDCE8" fill-opacity="0.8" stroke="#9B8BB8" stroke-width="2"/>
      <text x="60" y="-70" text-anchor="middle" font-family="Arial" font-size="32" font-weight="bold" fill="#5B5B85">MH</text>
      <text x="60" y="-45" text-anchor="middle" font-family="Arial" font-size="10" fill="#6B5B95">Memory Hierarchy</text>

      <!-- HBM - 우측 상단 (High Bandwidth Memory) -->
      <ellipse cx="80" cy="30" rx="110" ry="80" fill="#B8A8D8" fill-opacity="0.8" stroke="#9B8BB8" stroke-width="2"/>
      <text x="120" y="15" text-anchor="middle" font-family="Arial" font-size="32" font-weight="bold" fill="#5B5B85">HBM</text>
      <text x="120" y="40" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">High Bandwidth</text>
      <text x="120" y="52" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">Memory</text>

      <!-- CXL - 좌측 하단 (Compute Express Link) -->
      <ellipse cx="-80" cy="30" rx="110" ry="80" fill="#C8C8D8" fill-opacity="0.8" stroke="#9B8BB8" stroke-width="2"/>
      <text x="-120" y="15" text-anchor="middle" font-family="Arial" font-size="32" font-weight="bold" fill="#5B5B85">CXL</text>
      <text x="-120" y="42" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">Compute Express</text>
      <text x="-120" y="54" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">Link</text>

      <!-- PIM - 하단 좌측 (Processing-In-Memory) -->
      <ellipse cx="-30" cy="110" rx="110" ry="80" fill="#A898B8" fill-opacity="0.8" stroke="#9B8BB8" stroke-width="2"/>
      <text x="-60" y="105" text-anchor="middle" font-family="Arial" font-size="32" font-weight="bold" fill="#5B5B85">PIM</text>
      <text x="-60" y="130" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">Processing-In</text>
      <text x="-60" y="142" text-anchor="middle" font-family="Arial" font-size="9" fill="#6B5B95">Memory</text>

      <!-- Center Label - 겹치는 영역에 배치 -->
      <rect x="-75" y="-5" width="150" height="75" rx="8" fill="#6B5B95"/>
      <text x="0" y="20" text-anchor="middle" font-family="Arial" font-size="13" font-weight="bold" fill="white">Memory</text>
      <text x="0" y="38" text-anchor="middle" font-family="Arial" font-size="13" font-weight="bold" fill="white">Centric</text>
      <text x="0" y="56" text-anchor="middle" font-family="Arial" font-size="13" font-weight="bold" fill="white">Architecture</text>

      <!-- Center Icon -->
      <rect x="-20" y="-35" width="40" height="30" rx="4" fill="rgba(255,255,255,0.3)"/>
      <text x="0" y="-15" text-anchor="middle" font-family="Arial" font-size="16" fill="#6B5B95">⚡</text>
    </g>

    <!-- Left Description List -->
    <g transform="translate(20, 95)" font-family="Arial, sans-serif" fill="#333">
      <text font-size="9" font-weight="bold" fill="#6B5B95">• Tiered Storage:</text>
      <text x="0" y="12" font-size="8" fill="#666">Intelligent movement of data between</text>
      <text x="0" y="22" font-size="8" fill="#666">SRAM, HBM, and bulk DDR/SSD based on usage</text>
      <text x="0" y="32" font-size="8" fill="#666">frequency to balance cost and speed.</text>

      <text y="52" font-size="9" font-weight="bold" fill="#6B5B95">• Software-Managed Cache:</text>
      <text x="0" y="64" font-size="8" fill="#666">Moves away from hardware-</text>
      <text x="0" y="74" font-size="8" fill="#666">managed caches to software-controlled scratchpads for</text>
      <text x="0" y="84" font-size="8" fill="#666">predictable data movement in AI workloads.</text>

      <text y="104" font-size="9" font-weight="bold" fill="#6B5B95">• SRAM Optimization:</text>
      <text x="0" y="116" font-size="8" fill="#666">Maximizes on-chip SRAM</text>
      <text x="0" y="126" font-size="8" fill="#666">capacity to keep frequently used activation data</text>
      <text x="0" y="136" font-size="8" fill="#666">close to the arithmetic logic units (ALUs).</text>

      <text y="156" font-size="9" font-weight="bold" fill="#6B5B95">• Coherency:</text>
      <text x="0" y="168" font-size="8" fill="#666">Uses the CXL protocol to maintain</text>
      <text x="0" y="178" font-size="8" fill="#666">cache coherency between the host processor and</text>
      <text x="0" y="188" font-size="8" fill="#666">attached memory devices.</text>

      <text y="208" font-size="9" font-weight="bold" fill="#6B5B95">• Scalability:</text>
      <text x="0" y="220" font-size="8" fill="#666">Allows dynamic allocation of memory</text>
      <text x="0" y="230" font-size="8" fill="#666">capacity to workloads that need it most, preventing</text>
      <text x="0" y="240" font-size="8" fill="#666">resource stranding.</text>

      <text y="260" font-size="9" font-weight="bold" fill="#6B5B95">• Disaggregated Memory:</text>
      <text x="0" y="272" font-size="8" fill="#666">Decouples memory from</text>
      <text x="0" y="282" font-size="8" fill="#666">specific CPUs, creating a shared pool of memory</text>
      <text x="0" y="292" font-size="8" fill="#666">resources accessible by multiple accelerators.</text>
    </g>

    <!-- Right Description List -->
    <g transform="translate(720, 95)" font-family="Arial, sans-serif" fill="#333">
      <text font-size="9" font-weight="bold" fill="#6B5B95">• Vertical Stacking:</text>
      <text x="0" y="12" font-size="8" fill="#666">Utilizes 3D-stacked DRAM dies</text>
      <text x="0" y="22" font-size="8" fill="#666">(TSV technology) to drastically increase data</text>
      <text x="0" y="32" font-size="8" fill="#666">pathways compared to traditional DDR.</text>

      <text y="52" font-size="9" font-weight="bold" fill="#6B5B95">• Proximity:</text>
      <text x="0" y="64" font-size="8" fill="#666">Places memory stacks immediately next to</text>
      <text x="0" y="74" font-size="8" fill="#666">the compute die (GPU/NPU) via an interposer to</text>
      <text x="0" y="84" font-size="8" fill="#666">minimize latency.</text>

      <text y="104" font-size="9" font-weight="bold" fill="#6B5B95">• Bandwidth Maximization:</text>
      <text x="0" y="116" font-size="8" fill="#666">Delivers terabyte-scale</text>
      <text x="0" y="126" font-size="8" fill="#666">bandwidth essential for feeding data-hungry LLMs</text>
      <text x="0" y="136" font-size="8" fill="#666">without stalling compute cores.</text>

      <text y="156" font-size="9" font-weight="bold" fill="#6B5B95">• Compute Offloading:</text>
      <text x="0" y="168" font-size="8" fill="#666">Embeds programmable computing</text>
      <text x="0" y="178" font-size="8" fill="#666">units directly within the memory arrays to process data</text>
      <text x="0" y="188" font-size="8" fill="#666">where it is stored.</text>

      <text y="208" font-size="9" font-weight="bold" fill="#6B5B95">• Energy Reduction:</text>
      <text x="0" y="220" font-size="8" fill="#666">Eliminates the massive energy cost</text>
      <text x="0" y="230" font-size="8" fill="#666">of moving data back and forth between memory and</text>
      <text x="0" y="240" font-size="8" fill="#666">the processor.</text>

      <text y="260" font-size="9" font-weight="bold" fill="#6B5B95">• Parallel Efficiency:</text>
      <text x="0" y="272" font-size="8" fill="#666">Ideal for simple, repetitive arithmetic</text>
      <text x="0" y="282" font-size="8" fill="#666">operations (like element-wise functions) across vast</text>
      <text x="0" y="292" font-size="8" fill="#666">datasets.</text>
    </g>

    <!-- Copyright footer -->
    <text x="480" y="532" text-anchor="middle" font-family="Arial" font-size="7" fill="#999">
      Copyright 2026 | This infographic was created using data collected through Google's generative AI, Gemini. The data visualization was designed by Woo Seok Jin.
    </text>
  </svg>

shapes:
  - id: "center-label"
    name: "중앙 레이블"
    type: rounded_rectangle
    z_index: 15
    geometry:
      x: 38%
      y: 40%
      cx: 24%
      cy: 20%
      original_aspect_ratio: 1.2
    style:
      fill: {type: solid, color: "#6B5B95", opacity: 1.0}
      rounded_corners: 8
    text:
      has_text: true
      content: "Memory\nCentric\nArchitecture"
      alignment: center
      font_size_ratio: 0.026
      original_font_size_pt: 14
      font_weight: bold
      font_color: white

  - id: "segment-top"
    name: "MH (Memory Hierarchy)"
    type: oval
    z_index: 5
    geometry:
      x: 38%
      y: 20%
      cx: 21%
      cy: 26%
    style:
      fill: {type: solid, color: "#E8E0F0", opacity: 0.7}
      stroke: {color: "#9370DB", width: 2}
    content:
      abbreviation: "MH"
      full_name: "Memory Hierarchy"

  - id: "segment-right"
    name: "HBM (High Bandwidth Memory)"
    type: oval
    z_index: 5
    geometry:
      x: 50%
      y: 35%
      cx: 21%
      cy: 26%
    style:
      fill: {type: solid, color: "#C9B8D9", opacity: 0.7}
      stroke: {color: "#9370DB", width: 2}
    content:
      abbreviation: "HBM"
      full_name: "High Bandwidth Memory"

  - id: "segment-bottom"
    name: "PIM (Processing-In-Memory)"
    type: oval
    z_index: 5
    geometry:
      x: 38%
      y: 50%
      cx: 21%
      cy: 26%
    style:
      fill: {type: solid, color: "#B8A8C8", opacity: 0.7}
      stroke: {color: "#9370DB", width: 2}
    content:
      abbreviation: "PIM"
      full_name: "Processing-In-Memory"

  - id: "segment-left"
    name: "CXL (Compute Express Link)"
    type: oval
    z_index: 5
    geometry:
      x: 28%
      y: 35%
      cx: 21%
      cy: 26%
    style:
      fill: {type: solid, color: "#D8C8E8", opacity: 0.7}
      stroke: {color: "#9370DB", width: 2}
    content:
      abbreviation: "CXL"
      full_name: "Compute Express Link"

  - id: "desc-left"
    name: "왼쪽 설명 목록"
    type: textbox
    z_index: 10
    geometry:
      x: 2%
      y: 17%
      cx: 24%
      cy: 70%
    text:
      has_text: true
      content_type: bullet_list
      items:
        - {title: "Tiered Storage:", desc: "Intelligent movement of data between SRAM, HBM, and bulk DDR/SSD based on usage frequency to balance cost and speed."}
        - {title: "Software-Managed Cache:", desc: "Moves away from hardware-managed caches to software-controlled scratchpads for predictable data movement in AI workloads."}
        - {title: "SRAM Optimization:", desc: "Maximizes on-chip SRAM capacity to keep frequently used activation data close to the arithmetic logic units (ALUs)."}
        - {title: "Coherency:", desc: "Uses the CXL protocol to maintain cache coherency between the host processor and attached memory devices."}
        - {title: "Scalability:", desc: "Allows dynamic allocation of memory capacity to workloads that need it most, preventing resource stranding."}
        - {title: "Disaggregated Memory:", desc: "Decouples memory from specific CPUs, creating a shared pool of memory resources accessible by multiple accelerators."}

  - id: "desc-right"
    name: "오른쪽 설명 목록"
    type: textbox
    z_index: 10
    geometry:
      x: 75%
      y: 17%
      cx: 24%
      cy: 70%
    text:
      has_text: true
      content_type: bullet_list
      items:
        - {title: "Vertical Stacking:", desc: "Utilizes 3D-stacked DRAM dies (TSV technology) to drastically increase data pathways compared to traditional DDR."}
        - {title: "Proximity:", desc: "Places memory stacks immediately next to the compute die (GPU/NPU) via an interposer to minimize latency."}
        - {title: "Bandwidth Maximization:", desc: "Delivers terabyte-scale bandwidth essential for feeding data-hungry LLMs without stalling compute cores."}
        - {title: "Compute Offloading:", desc: "Embeds programmable computing units directly within the memory arrays to process data where it is stored."}
        - {title: "Energy Reduction:", desc: "Eliminates the massive energy cost of moving data back and forth between memory and the processor."}
        - {title: "Parallel Efficiency:", desc: "Ideal for simple, repetitive arithmetic operations (like element-wise functions) across vast datasets."}

gaps:
  global: {column_gap: 3%, row_gap: 3%}

spatial_relationships:
  - type: venn_overlap
    center: center-label
    segments: [segment-top, segment-right, segment-bottom, segment-left]

groups: []

thumbnail: thumbnails/matrix/venn-4segment1.png

use_for:
  - "기술 아키텍처"
  - "개념 관계도"
  - "4가지 핵심 요소"
  - "시스템 구조"
  - "기술 스택"

keywords:
  - "벤 다이어그램"
  - "4분할"
  - "겹침"
  - "아키텍처"
  - "관계도"
  - "기술"
  - "메모리"

expected_prompt: |
  4개의 원이 겹치는 벤 다이어그램 슬라이드를 만들어줘.
  - 중앙에 핵심 개념 라벨 (보라색 배경)
  - 4개의 타원이 중앙을 향해 겹침
  - 좌우에 각 요소에 대한 상세 설명 목록
  - 보라색 계열의 그라데이션 색상

prompt_keywords: ["벤다이어그램", "4개", "겹침", "아키텍처", "기술", "관계"]
