
> 이미지에서 각각의 텍스트의 위치와 크기, 오브젝트의 위치, 크기, 형태(일반 도형, SVG, 
이미지) 등을 잘 추출할 수 있는 방법을 연구해줘. 
  ⎿ ⧉ Selected 81 lines from templates\contents\templates\cycle\cycle-4arrow1.yaml in
    Antigravity

● 이미지에서 레이아웃 정보를 추출하는 방법을 연구하겠습니다. 현재 시스템과 가능한 접근법을 탐색합니다.

● Explore(이미지 분석 관련 코드 탐색)
  ⎿  Done (19 tool uses · 93.7k tokens · 1m 43s)

● Web Search("image layout extraction OCR text position detection python 2025")
  ⎿  Did 1 search in 26s

● Web Search("document layout analysis AI model detectron2 layoutparser 2025")
  ⎿  Did 1 search in 22s

● Web Search("Claude Vision API GPT-4V image analysis layout extraction bounding box 2025")
  ⎿  Did 1 search in 26s

● Web Search("YOLO object detection document layout slide PPT analysis 2025")
  ⎿  Did 1 search in 24s

● 연구 결과를 정리했습니다.

  이미지에서 레이아웃 추출 연구 결과

  현재 시스템 vs 이미지 분석

  | 입력      | 현재 방식              | 정확도                |
  |-----------|------------------------|-----------------------|
  | PPTX 파일 | python-pptx + XML 파싱 | ✅ 100% (원본 데이터) |
  | 이미지만  | ❌ 미지원              | -                     |

  문제: 이미지만 있을 때 텍스트/도형 위치를 추출할 방법이 없음

  ---
  접근법 비교

  | 방식        | 도구                                                                                                         |  장점                     | 단점                                                          |
  |-------------|--------------------------------------------------------------------------------------------------------------|--------------------------|---------------------------------------------------------------|
  | OCR 기반    | Tesseract, EasyOCR, DocTR                                                                                    |  텍스트 위치/크기 정확    | 도형/SVG 인식 불가                                            |
  | 레이아웃 AI | https://github.com/Layout-Parser/layout-parser + Detectron2                                                  |  문서 구조 분석           | 슬라이드 특화 아님                                            |
  | YOLO        | https://digitalsoftware.co/2025/04/07/yolov12-enhanced-efficiency-and-accuracy-for-document-layout-analysis/ |  빠름, 슬라이드 요소 감지 | 커스텀 학습 필요                                              |
  | 멀티모달 AI | Claude Vision, GPT-4V                                                                                        |  해석력 우수              | https://github.com/Doriandarko/Claude-Vision-Object-Detection |

  ---
  권장 하이브리드 파이프라인

  이미지 입력
      ↓
  ┌─────────────────────────────────────┐
  │ Stage 1: 객체 감지 (YOLO/LayoutParser) │
  ├─────────────────────────────────────┤
  │ - 텍스트 영역 bounding box          │
  │ - 도형 영역 (사각형, 원, 화살표)      │
  │ - 이미지 영역                        │
  │ - 차트/테이블 영역                   │
  └─────────────────────────────────────┘
      ↓
  ┌─────────────────────────────────────┐
  │ Stage 2: OCR (Tesseract/EasyOCR)    │
  ├─────────────────────────────────────┤
  │ - 각 텍스트 영역 OCR                 │
  │ - 텍스트 위치, 크기, 폰트 추정       │
  └─────────────────────────────────────┘
      ↓
  ┌─────────────────────────────────────┐
  │ Stage 3: 해석 (Claude Vision)       │
  ├─────────────────────────────────────┤
  │ - 레이아웃 의도 분석                 │
  │ - 색상 팔레트 추출                   │
  │ - 디자인 패턴 분류                   │
  └─────────────────────────────────────┘
      ↓
  YAML 템플릿 출력

  ---
  구현 제안: image-layout-extractor.py

  """
  이미지에서 슬라이드 레이아웃 추출
  Dependencies: layoutparser, pytesseract, PIL, opencv-python
  """

  # Stage 1: 객체 감지
  import layoutparser as lp

  model = lp.Detectron2LayoutModel(
      config_path='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',
      label_map={0: "Text", 1: "Title", 2: "List", 3: "Table", 4: "Figure"}
  )

  layout = model.detect(image)

  # Stage 2: OCR
  import pytesseract

  for block in layout:
      if block.type in ["Text", "Title", "List"]:
          cropped = image.crop(block.coordinates)
          text_data = pytesseract.image_to_data(cropped, output_type=pytesseract.Output.DICT)
          # text_data contains: x, y, width, height, text, conf

  # Stage 3: 구조화
  output = {
      "canvas": {"width": img_width, "height": img_height},
      "shapes": [
          {
              "id": f"text-{i}",
              "type": "textbox",
              "geometry": {"x": f"{x/img_width*100:.1f}%", ...},
              "text": extracted_text
          }
          ...
      ]
  }

  ---
  실제 사례: https://www.ultralytics.com/customers/prezent-turns-to-ultralytics-yolo-models-to-detect-slide-elements

  YOLO 모델로 슬라이드 요소(제목, 텍스트박스, 이미지, 차트) 자동 감지
  - 정확도: 65% → 87%
  - 처리 시간: 10초 미만/슬라이드

  ---
  다음 단계 제안

  1. LayoutParser 프로토타입 - 기존 슬라이드 이미지로 테스트
  2. 커스텀 YOLO 학습 - 슬라이드 특화 데이터셋 구축 (DocLayNet 활용)
  3. Claude Vision 통합 - 디자인 의도 분석에 활용